# 버전별 개선 히스토리

> **목적**: 각 기능이 어떻게 발전해왔는지 Before → After 구조로 기록
> **대상**: 팀원(기획자, 디자이너, 의사결정자)
> **최종 수정**: 2026-01-15

---

## 문서 구조 안내

각 기능별로 아래 구조로 기록합니다:

```
## [기능명]

### v1.0 (날짜) - 초기 구현
- Before: 없었던 상태
- After: 구현된 상태
- 측정값: 수치

### v1.1 (날짜) - 1차 개선
- 문제: 뭐가 안 됐다
- 변경: 뭘 바꿨다
- Before → After: 비교
```

---

# 1. 음성 인식 (STT)

> 사용자가 영어로 말하면 텍스트로 변환하는 기능

## v1.0 (2026-01-12) - 초기 구현

### 상태
| 항목 | 내용 |
|------|------|
| 방식 | Web Speech API (브라우저 내장) |
| 지원 브라우저 | Chrome, Edge만 |
| 특징 | 별도 서버 불필요, 무료 |

### 동작
```
사용자 말하기 → 브라우저가 인식 → 텍스트 출력
```

### 측정값
| 지표 | 값 | 평가 |
|------|-----|------|
| 레이턴시 | ~300ms | 좋음 |
| 인식률 | ~70% | 아쉬움 |
| 브라우저 지원 | Chrome만 | 부족 |

### 한계
- Safari, Firefox 미지원
- 네트워크 끊기면 동작 안 함
- 인식률이 AWS 대비 낮음

---

## v1.1 (2026-01-12) - AWS Transcribe Batch 추가

### 문제
> "Web Speech API는 Chrome에서만 동작해서 iOS Safari 사용자는 쓸 수 없다"

### 변경
- AWS Transcribe (Batch 방식) 추가
- 녹음 → S3 업로드 → 변환 → 결과 수신

### Before → After
| 항목 | Before (v1.0) | After (v1.1) |
|------|---------------|--------------|
| 지원 브라우저 | Chrome만 | 모든 브라우저 |
| 인식률 | ~70% | ~85% |
| **레이턴시** | ~300ms | **3~5초** |

### 트레이드오프
```
✅ 해결: 브라우저 호환성
❌ 발생: 레이턴시 급증 (300ms → 3~5초)
```

### 원인 분석
```
녹음 완료 (0ms)
  ↓ S3 업로드 (~500ms)
  ↓ Transcribe Job 생성 (~500ms)
  ↓ 폴링 대기 (2~3초, 1초 간격)
  ↓ 결과 수신
= 총 3~5초
```

---

## v1.2 (2026-01-13) - Streaming STT 시도

### 문제
> "Batch 방식의 3~5초 대기는 자연스러운 대화에 치명적"

### 변경
- AWS Transcribe Streaming (WebSocket) 구현 시도
- 실시간으로 오디오 전송 → 실시간 텍스트 수신

### 기술적 시도
```javascript
// WebSocket으로 실시간 오디오 전송
const websocket = new WebSocket(presignedUrl)
websocket.send(audioChunk)  // 256ms마다 전송
```

### 결과
| 항목 | 시도 | 결과 |
|------|------|------|
| 직접 구현 | CRC32C 직접 작성 | ❌ "Could not decode audio" 오류 |
| AWS SDK 사용 | @aws-sdk/eventstream-codec | ✅ 인코딩 성공 |

### Before → After
| 항목 | Before (v1.1) | After (v1.2) |
|------|---------------|--------------|
| 방식 | Batch (S3 업로드) | Streaming (WebSocket) |
| 레이턴시 | 3~5초 | 테스트 중 (목표: 500ms) |

### 현재 상태
```
🔄 진행중 - Streaming 연결 성공, 실제 레이턴시 측정 필요
```

---

## v1.3 (예정) - Streaming 최적화

### 목표
| 지표 | 현재 | 목표 |
|------|------|------|
| STT 레이턴시 | 3~5초 | **< 500ms** |
| 인식률 | ~85% | 90%+ |

### 계획
1. Streaming 레이턴시 실측
2. 오디오 전처리 (노이즈 제거)
3. VAD 파라미터 튜닝

---

# 2. AI 응답 생성 (LLM)

> AI가 사용자 말을 이해하고 영어로 응답하는 기능

## v1.0 (2026-01-12) - 초기 구현

### 상태
| 항목 | 내용 |
|------|------|
| 모델 | Claude 3 Haiku (AWS Bedrock) |
| 응답 길이 | max_tokens: 300 |
| 프롬프트 | 기본 영어 튜터 역할 |

### 동작
```
사용자 텍스트 + 대화 기록 → Claude API → AI 응답
```

### 측정값
| 지표 | 값 | 평가 |
|------|-----|------|
| 레이턴시 | 1~2초 | 비슷 |
| 응답 품질 | 자연스러움 | 좋음 |

---

## v1.1 (2026-01-12) - 프롬프트 개선

### 문제
> "AI가 매번 'Hello! Nice to meet you!'로 인사를 반복한다"

### 변경
프롬프트에 규칙 추가:
```
CRITICAL RULES:
1. NEVER re-introduce yourself after the first message
2. NEVER say "Hello", "Hi there" after conversation started
3. Keep responses SHORT: 1-2 sentences only
```

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 첫 인사 | 매번 "Hello!" | 첫 번째만 인사 |
| 응답 길이 | 3~4문장 | 1~2문장 |
| 자연스러움 | 로봇 같음 | 친구 같음 |

---

## v1.2 (2026-01-12) - 설정 반영

### 변경
사용자 설정(억양, 난이도, 주제)을 프롬프트에 반영

```python
SYSTEM_PROMPT = """
Context:
- Accent: {accent}     # American/British/Australian/Indian
- Level: {level}       # Beginner/Intermediate/Advanced
- Topic: {topic}       # Business/Daily/Travel/Interview
"""
```

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 억양 반영 | 미국식만 | 4개국 스타일 |
| 난이도 반영 | 고정 | 3단계 |
| 주제 반영 | 없음 | 4개 주제 |

---

# 3. 음성 합성 (TTS)

> AI 응답 텍스트를 음성으로 변환하는 기능

## v1.0 (2026-01-12) - 초기 구현

### 상태
| 항목 | 내용 |
|------|------|
| 서비스 | Amazon Polly |
| 음성 엔진 | Neural (고품질) |
| 목소리 | Joanna (미국 여성) 고정 |

### 측정값
| 지표 | 값 | 평가 |
|------|-----|------|
| 레이턴시 | 500ms~1초 | 비슷 |
| 음성 품질 | 자연스러움 | 좋음 |

---

## v1.1 (2026-01-12) - 목소리 다양화

### 문제
> "항상 같은 목소리라서 튜터 설정이 의미 없다"

### 변경
억양+성별 조합별 목소리 매핑:

| 억양 | 여성 | 남성 | 엔진 |
|------|------|------|------|
| 미국 | Joanna | Matthew | Neural |
| 영국 | Amy | Brian | Neural |
| 호주 | Nicole | Russell | Standard |
| 인도 | Aditi | Aditi | Standard |

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 목소리 종류 | 1개 | 8개 |
| 설정 반영 | 안 됨 | 억양+성별 반영 |

### 한계
- 호주/인도는 Neural 미지원 → Standard 사용 (품질 차이)

---

## v1.2 (2026-01-12) - 속도 조절 추가

### 변경
```python
# Polly SSML로 속도 조절
speed_map = {
    'slow': 'slow',
    'normal': 'medium',
    'fast': 'fast'
}
ssml = f'<speak><prosody rate="{speed}">{text}</prosody></speak>'
```

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 속도 옵션 | 없음 | 3단계 (0.8x/1.0x/1.2x) |

---

# 4. 실시간 대화 (E2E)

> 전체 대화 흐름의 성능

## v1.0 (2026-01-12) - 초기 상태

### 측정값
```
사용자 말 (~2초)
  ↓ STT: Web Speech (~300ms)
  ↓ LLM: Claude (~1.5초)
  ↓ TTS: Polly (~700ms)
= E2E: ~2.5초
```

| 지표 | 값 | 평가 |
|------|-----|------|
| E2E 레이턴시 | ~2.5초 | 비슷 |

### 한계
- Chrome에서만 동작

---

## v1.1 (2026-01-12) - AWS STT 적용 후

### 변경
- Web Speech API → AWS Transcribe Batch

### Before → After
| 항목 | Before (v1.0) | After (v1.1) |
|------|---------------|--------------|
| STT | 300ms | **3~5초** |
| E2E | 2.5초 | **5~8초** |
| 브라우저 지원 | Chrome만 | 모든 브라우저 |

### 트레이드오프
```
✅ 해결: 브라우저 호환성
❌ 발생: E2E 레이턴시 2배 증가
```

---

## v1.2 (2026-01-13) - Streaming STT 적용 후 (진행중)

### 목표
| 항목 | 현재 (v1.1) | 목표 (v1.2) |
|------|-------------|-------------|
| STT | 3~5초 | 500ms |
| LLM | 1.5초 | 1초 |
| TTS | 700ms | 300ms |
| **E2E** | **5~8초** | **< 2초** |

### 상태
```
🔄 진행중 - Streaming STT 테스트 단계
```

---

# 5. 대화 스크립트 (자막)

> 통화 중 실시간 자막 표시

## v1.0 (2026-01-12) - 초기 구현

### 상태
- AI/사용자 메시지 화면 표시
- 영어만 표시

---

## v1.1 (2026-01-12) - 자막 모드 추가

### 문제
> "초급자는 번역이 필요하고, 고급자는 영어만 보고 싶다"

### 변경
4가지 자막 모드:
1. 모두 보기 (영어 + 한국어)
2. 영어만
3. 번역만
4. 끄기

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 자막 옵션 | 없음 | 4가지 모드 |
| 번역 | 없음 | AWS Translate |

---

## v1.2 (2026-01-13) - 자막 버튼 개선

### 문제
> "자막 버튼이 항상 'Subtitle'로만 표시되어 현재 상태를 모른다"

### 변경
버튼 텍스트가 현재 모드를 표시:
```javascript
const SUBTITLE_BUTTON_LABELS = {
  all: '모두 보기',
  english: '영어만',
  translation: '번역만',
  off: '자막 끄기'
}
```

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 버튼 텍스트 | "Subtitle" 고정 | 현재 모드 표시 |

---

# 6. AI 분석 리포트

> 통화 종료 후 영어 실력 분석

## v1.0 (2026-01-12) - 초기 구현

### 상태
- CAFP 점수 (Complexity, Accuracy, Fluency, Pronunciation)
- 문법 교정
- 필러워드 분석
- 종합 피드백

### 측정값
| 지표 | 값 | 평가 |
|------|-----|------|
| 분석 속도 | 2~4초 | 비슷 |
| 분석 항목 | 4개 영역 | 좋음 |

---

## v1.1 (2026-01-12) - 최소 단어 수 제한

### 문제
> "5단어만 말해도 분석 요청이 되는데, 결과가 의미 없다"

### 변경
- 최소 30단어 이상일 때만 분석 가능
- 미달 시 토스트 알림

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 분석 조건 | 무조건 가능 | 30단어 이상 |
| 안내 | 없음 | 토스트 알림 |

---

## v1.2 (2026-01-13) - 분석 페이지 분리

### 문제
> "결과 화면에서 바로 분석 결과가 나오니 로딩이 길다"

### 변경
- Result 페이지: 통계만 표시 (빠름)
- Analysis 페이지: AI 분석 결과 (별도)

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 결과 화면 로딩 | 2~4초 | 즉시 |
| 분석 | 자동 | 버튼 클릭 시 |

---

# 7. 교정 연습

> AI가 찾아낸 문법 오류를 연습하는 기능

## v1.0 (2026-01-12) - 초기 구현

### 상태
- 3단계 연습: 설명 → 따라 말하기 → 완료
- 정확도 계산: 단순 문자열 비교

---

## v1.1 (2026-01-12) - 정확도 계산 개선

### 문제
> "한 글자만 틀려도 0%가 나온다"

### 변경
Levenshtein Distance 알고리즘 적용:
- 글자 유사도 40% + 단어 매칭 60%

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 알고리즘 | 완전 일치 | Levenshtein |
| 점수 분포 | 0% or 100% | 0~100% 연속 |

---

# 8. 튜터 설정

## v1.0 (2026-01-12) - 초기 구현

### 상태
- 억양/성별/속도/난이도/주제 선택
- LocalStorage 저장

---

## v1.1 (2026-01-12) - 서버 동기화

### 문제
> "다른 기기에서 접속하면 설정이 초기화된다"

### 변경
- DynamoDB에 설정 저장
- 기기 간 동기화

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 저장 위치 | LocalStorage만 | Local + DynamoDB |
| 기기 동기화 | 안 됨 | 됨 |

---

## v1.2 (2026-01-12) - UI 개선

### 변경
- 링글 앱 스타일 섹션 리스트
- 저장 시 토스트 알림

---

# 9. 세션 관리

## v1.0 (2026-01-12) - 초기 구현

### 상태
- 통화 기록 LocalStorage 저장
- 최대 10개 유지

---

## v1.1 (2026-01-12) - DynamoDB 연동

### 문제
> "LocalStorage는 브라우저별로 따로라서 기록이 공유 안 된다"

### 변경
- 세션/메시지 DynamoDB 저장
- 페이지네이션 조회

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 저장 위치 | LocalStorage | DynamoDB |
| 저장 개수 | 10개 제한 | 무제한 |
| 기기 동기화 | 안 됨 | 됨 |

---

## v1.2 (2026-01-13) - 쿼리 버그 수정

### 문제
> "세션 목록이 안 나온다 - 빈 배열만 반환"

### 원인
DynamoDB `Limit`이 `FilterExpression` 전에 적용됨
→ 100개 중 MESSAGE가 많으면 SESSION_META가 안 잡힘

### 변경
페이지네이션 루프로 SESSION_META를 충분히 찾을 때까지 반복

### Before → After
| 항목 | Before | After |
|------|--------|-------|
| 세션 목록 | 빈 배열 | 정상 표시 |

---

# 요약 테이블

| 기능 | 초기 버전 | 현재 버전 | 주요 개선 | 상태 |
|------|----------|----------|----------|------|
| 음성 인식 | v1.0 | v1.2 | Streaming STT | 🔄 진행중 |
| AI 응답 | v1.0 | v1.2 | 프롬프트 개선, 설정 반영 | ✅ 완료 |
| 음성 합성 | v1.0 | v1.2 | 8개 목소리, 속도 조절 | ✅ 완료 |
| E2E 대화 | v1.0 | v1.1 | (STT 병목으로 악화) | 🔄 진행중 |
| 대화 스크립트 | v1.0 | v1.2 | 4가지 자막 모드 | ✅ 완료 |
| AI 분석 | v1.0 | v1.2 | 페이지 분리, 최소 단어 | ✅ 완료 |
| 교정 연습 | v1.0 | v1.1 | Levenshtein 정확도 | ✅ 완료 |
| 튜터 설정 | v1.0 | v1.2 | 서버 동기화, UI 개선 | ✅ 완료 |
| 세션 관리 | v1.0 | v1.2 | DynamoDB, 버그 수정 | ✅ 완료 |

---

# 다음 버전 예정

| 기능 | 다음 버전 | 목표 |
|------|----------|------|
| 음성 인식 | v1.3 | STT 레이턴시 < 500ms |
| E2E 대화 | v1.2 | E2E 레이턴시 < 2초 |
| AI 분석 | v1.3 | 실제 발음 분석 |

---

*이 문서는 새로운 버전이 추가될 때마다 업데이트됩니다.*
